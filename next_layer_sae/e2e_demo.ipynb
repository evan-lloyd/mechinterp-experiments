{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d465fbd",
   "metadata": {
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://colab.research.google.com/github/evan-lloyd/mechinterp-experiments/blob/main/next_layer_sae/e2e_demo.ipynb\" target=\"_blank\" id=\"colab-button\">\n",
       "            <button style=\"background-color: #4285f4; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer; font-size: 14px;\">\n",
       "                Run this notebook in Google Colab\n",
       "            </button>\n",
       "        </a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        setTimeout(() => {\n            if(typeof google.colab != \"undefined\") {\n                document.querySelector(\"#colab-button\").remove()\n            }\n        }, 0);\n        ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Running in Colab\n",
    "\n",
    "from IPython.display import HTML, Javascript, display\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        \"\"\"<a href=\"https://colab.research.google.com/github/evan-lloyd/mechinterp-experiments/blob/main/next_layer_sae/e2e_demo.ipynb\" target=\"_blank\" id=\"colab-button\">\n",
    "            <button style=\"background-color: #4285f4; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer; font-size: 14px;\">\n",
    "                Run this notebook in Google Colab\n",
    "            </button>\n",
    "        </a>\"\"\"\n",
    "    )\n",
    ")\n",
    "display(\n",
    "    Javascript(\"\"\"\n",
    "        setTimeout(() => {\n",
    "            if(typeof google.colab != \"undefined\") {\n",
    "                document.querySelector(\"#colab-button\").remove()\n",
    "            }\n",
    "        }, 0);\n",
    "        \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03231229",
   "metadata": {},
   "source": [
    "# Initialize notebook environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b73c6d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already cloned source, or not running in Colab.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# If we're running in Colab, we need to clone the non-notebook source from git.\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\") and not os.path.isdir(\n",
    "    \"/content/mechinterp-experiments\"\n",
    "):\n",
    "    ip = get_ipython()  #  pyright: ignore[reportUndefinedVariable]\n",
    "    ip.run_cell_magic(\n",
    "        \"bash\",\n",
    "        \"\",\n",
    "        \"\"\"\n",
    "    git clone --filter=blob:none --no-checkout https://github.com/evan-lloyd/mechinterp-experiments.git\n",
    "    cd mechinterp-experiments\n",
    "    git sparse-checkout init --no-cone\n",
    "    echo \"/next_layer_sae\" > .git/info/sparse-checkout\n",
    "    git checkout\n",
    "  \"\"\",\n",
    "    )\n",
    "    ip.run_line_magic(\"cd\", \"mechinterp-experiments/next_layer_sae\")\n",
    "else:\n",
    "    print(\"Already cloned source, or not running in Colab.\")\n",
    "\n",
    "# Nice for dev, but not needed for Colab.\n",
    "try:\n",
    "    # This uses a library called jurigged to hot-reload code when it is changed.\n",
    "    # For reasons I've never been able to figure out, the IPython %autoreload magic\n",
    "    # completely fails to work with the kind of structure I use in this notebook.\n",
    "    import _autoreload\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ab8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTNeoForCausalLM(\n",
      "  (transformer): GPTNeoModel(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(2048, 768)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-3): 4 x GPTNeoBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPTNeoAttention(\n",
      "          (attention): GPTNeoSelfAttention(\n",
      "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPTNeoMLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Tweak TRAINING_BATCH_SIZE for your hardware if necessary\n",
    "if torch.cuda.is_available():\n",
    "    TRAINING_DEVICE = \"cuda\"\n",
    "    TRAINING_BATCH_SIZE = 64\n",
    "elif torch.mps.is_available():\n",
    "    TRAINING_DEVICE = \"mps\"\n",
    "    TRAINING_BATCH_SIZE = 8\n",
    "else:\n",
    "    TRAINING_DEVICE = \"cpu\"\n",
    "    TRAINING_BATCH_SIZE = 8\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "training_dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\", streaming=True)\n",
    "validation_dataset = load_dataset(\n",
    "    \"roneneldan/TinyStories\", split=\"validation\", streaming=True\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"roneneldan/TinyStories-33M\").to(\n",
    "    TRAINING_DEVICE\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9370002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caches model activations to these directories; modify if necessary, or set to None to disable.\n",
    "# These take up ~XXGB and ~XXGB respectively, but will save a fair bit of time when running\n",
    "# the notebook, since they can be re-used across all methods we're comparing.\n",
    "TRAINING_CACHE_DIR = \".training_cache\"\n",
    "VALIDATION_CACHE_DIR = \".validation_cache\"\n",
    "NUM_TRAINING_TOKENS = 1e6\n",
    "EVAL_INTERVAL = 1e5\n",
    "NUM_VALIDATION_TOKENS = 1e5\n",
    "D_MODEL = model.config.hidden_size\n",
    "D_SAE = D_MODEL * 4\n",
    "TOKENIZER_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab753f0",
   "metadata": {},
   "source": [
    "# Train SAEs for comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef1f1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from next_layer_sae.sae import SAE\n",
    "from next_layer_sae.training import TrainingConfig, train\n",
    "\n",
    "saes = {\n",
    "    method: {\n",
    "        layer: SAE(\n",
    "            D_MODEL,\n",
    "            D_SAE,\n",
    "            device=model.device,\n",
    "            kind=\"topk\",\n",
    "            topk=100,\n",
    "        )\n",
    "        for layer in range(model.config.num_layers)\n",
    "    }\n",
    "    for method in [\"next_layer\", \"e2e\", \"finetuned\"]\n",
    "}\n",
    "\n",
    "training_config = TrainingConfig(\n",
    "    tokenizer_batch_size=TOKENIZER_BATCH_SIZE,\n",
    "    training_batch_size=TRAINING_BATCH_SIZE,\n",
    "    num_train_tokens=int(1e6),\n",
    "    dense_weight=0.01,\n",
    "    idempotency_weight=[2.0, 2.0, 2.0, 2.0],\n",
    "    eval_interval=int(1e5),\n",
    "    train_layers=list(range(model.config.num_layers)),\n",
    "    lr=1e-3,\n",
    "    use_next_layer_sae=True,\n",
    "    next_reconstruction_weight=1.0,\n",
    "    reconstruction_weight=1.0,\n",
    "    use_kl_on_final_layer=True,\n",
    "    balance_reconstruction_losses=True,\n",
    "    use_weighted_mask=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0137f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe7f65e091443aaa5c1ce8c0daa8bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building activation cache:   0%|          | 0/1000000.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from next_layer_sae.training import build_cache\n",
    "\n",
    "if TRAINING_CACHE_DIR and (\n",
    "    not os.path.exists(TRAINING_CACHE_DIR) or not os.listdir(TRAINING_CACHE_DIR)\n",
    "):\n",
    "    build_cache(\n",
    "        TRAINING_CACHE_DIR,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        training_dataset,\n",
    "        tokenizer_batch_size=TOKENIZER_BATCH_SIZE,\n",
    "        inference_batch_size=TRAINING_BATCH_SIZE,\n",
    "        num_tokens=NUM_TRAINING_TOKENS,\n",
    "    )\n",
    "\n",
    "if VALIDATION_CACHE_DIR and (\n",
    "    not os.path.exists(VALIDATION_CACHE_DIR) or not os.listdir(VALIDATION_CACHE_DIR)\n",
    "):\n",
    "    build_cache(\n",
    "        VALIDATION_CACHE_DIR,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        validation_dataset,\n",
    "        tokenizer_batch_size=TOKENIZER_BATCH_SIZE,\n",
    "        inference_batch_size=TRAINING_BATCH_SIZE,\n",
    "        num_tokens=NUM_VALIDATION_TOKENS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a6b425",
   "metadata": {},
   "source": [
    "## Next-layer auxiliary loss (my method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    saes[\"next_layer\"],\n",
    "    training_dataset,\n",
    "    training_config,\n",
    "    cache_dir=TRAINING_CACHE_DIR,\n",
    "    reinit_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038ed6e",
   "metadata": {},
   "source": [
    "## Full end-to-end training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f2ff90",
   "metadata": {},
   "source": [
    "## End-to-end fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce323e",
   "metadata": {},
   "source": [
    "# Evaluations and comparisons\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
