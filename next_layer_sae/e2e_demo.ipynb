{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d465fbd",
   "metadata": {
    "cellView": "form",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://colab.research.google.com/github/evan-lloyd/mechinterp-experiments/blob/main/next_layer_sae/e2e_demo.ipynb\" target=\"_blank\" id=\"colab-button\">\n",
       "            <button style=\"background-color: #4285f4; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer; font-size: 14px;\">\n",
       "                Run this notebook in Google Colab\n",
       "            </button>\n",
       "        </a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        setTimeout(() => {\n            if(typeof google.colab != \"undefined\") {\n                document.querySelector(\"#colab-button\").remove()\n            }\n        }, 0);\n        ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Running in Colab\n",
    "\n",
    "from IPython.display import HTML, Javascript, display\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        \"\"\"<a href=\"https://colab.research.google.com/github/evan-lloyd/mechinterp-experiments/blob/main/next_layer_sae/e2e_demo.ipynb\" target=\"_blank\" id=\"colab-button\">\n",
    "            <button style=\"background-color: #4285f4; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer; font-size: 14px;\">\n",
    "                Run this notebook in Google Colab\n",
    "            </button>\n",
    "        </a>\"\"\"\n",
    "    )\n",
    ")\n",
    "display(\n",
    "    Javascript(\"\"\"\n",
    "        setTimeout(() => {\n",
    "            if(typeof google.colab != \"undefined\") {\n",
    "                document.querySelector(\"#colab-button\").remove()\n",
    "            }\n",
    "        }, 0);\n",
    "        \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03231229",
   "metadata": {},
   "source": [
    "# Initialize notebook environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73c6d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already cloned source, or not running in Colab.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# If we're running in Colab, we need to clone the non-notebook source from git.\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\") and not os.path.isdir(\n",
    "    \"/content/mechinterp-experiments\"\n",
    "):\n",
    "    ip = get_ipython()  #  pyright: ignore[reportUndefinedVariable]\n",
    "    ip.run_cell_magic(\n",
    "        \"bash\",\n",
    "        \"\",\n",
    "        \"\"\"\n",
    "    git clone --filter=blob:none --no-checkout https://github.com/evan-lloyd/mechinterp-experiments.git\n",
    "    cd mechinterp-experiments\n",
    "    git sparse-checkout init --no-cone\n",
    "    echo \"/next_layer_sae\" > .git/info/sparse-checkout\n",
    "    git checkout\n",
    "  \"\"\",\n",
    "    )\n",
    "    ip.run_line_magic(\"cd\", \"mechinterp-experiments/next_layer_sae\")\n",
    "else:\n",
    "    print(\"Already cloned source, or not running in Colab.\")\n",
    "\n",
    "# Nice for dev, but not needed for Colab.\n",
    "try:\n",
    "    # This uses a library called jurigged to hot-reload code when it is changed.\n",
    "    # For reasons I've never been able to figure out, the IPython %autoreload magic\n",
    "    # completely fails to work with the kind of structure I use in this notebook.\n",
    "    import next_layer_sae._autoreload\n",
    "except Exception:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca2ab8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTNeoForCausalLM(\n",
      "  (transformer): GPTNeoModel(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(2048, 768)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-3): 4 x GPTNeoBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPTNeoAttention(\n",
      "          (attention): GPTNeoSelfAttention(\n",
      "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPTNeoMLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Tweak TRAINING_BATCH_SIZE for your hardware if necessary\n",
    "if torch.cuda.is_available():\n",
    "    TRAINING_DEVICE = \"cuda\"\n",
    "    TRAINING_BATCH_SIZE = 64\n",
    "elif torch.mps.is_available():\n",
    "    TRAINING_DEVICE = \"mps\"\n",
    "    TRAINING_BATCH_SIZE = 8\n",
    "else:\n",
    "    TRAINING_DEVICE = \"cpu\"\n",
    "    TRAINING_BATCH_SIZE = 8\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "training_dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\", streaming=True)\n",
    "validation_dataset = load_dataset(\n",
    "    \"roneneldan/TinyStories\", split=\"validation\", streaming=True\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"roneneldan/TinyStories-33M\").to(\n",
    "    TRAINING_DEVICE\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9370002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caches model activations to these directories; modify if necessary, or set to None to disable.\n",
    "# These take up ~16GB and ~1.5GB respectively, but will save a fair bit of time when running\n",
    "# the notebook, since they can be re-used across all methods we're comparing.\n",
    "TRAINING_CACHE_DIR = \".training_cache\"\n",
    "VALIDATION_CACHE_DIR = \".validation_cache\"\n",
    "NUM_TRAINING_TOKENS = 1e6\n",
    "EVAL_INTERVAL = 1e5\n",
    "NUM_VALIDATION_TOKENS = 1e5\n",
    "D_MODEL = model.config.hidden_size\n",
    "D_SAE = D_MODEL * 4\n",
    "TOKENIZER_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab753f0",
   "metadata": {},
   "source": [
    "# Train SAEs for comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef1f1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from next_layer_sae.sae import SAE\n",
    "from next_layer_sae.training import TrainingConfig, TrainingMethod, train\n",
    "\n",
    "saes = {\n",
    "    method: {\n",
    "        layer: SAE(\n",
    "            D_MODEL,\n",
    "            D_SAE,\n",
    "            device=model.device,\n",
    "            kind=\"topk\",\n",
    "            topk=100,\n",
    "        )\n",
    "        for layer in range(model.config.num_layers)\n",
    "    }\n",
    "    for method in TrainingMethod\n",
    "}\n",
    "\n",
    "training_config = {\n",
    "    method: TrainingConfig(\n",
    "        tokenizer_batch_size=TOKENIZER_BATCH_SIZE,\n",
    "        training_batch_size=TRAINING_BATCH_SIZE,\n",
    "        num_train_tokens=int(1e6),\n",
    "        dense_weight=0.0,\n",
    "        idempotency_weight=0.0,\n",
    "        eval_interval=int(1e5),\n",
    "        train_layers=list(range(model.config.num_layers)),\n",
    "        lr=1e-3,\n",
    "        use_next_layer_sae=method is TrainingMethod.next_layer,\n",
    "        next_reconstruction_weight=1.0 if method is TrainingMethod.next_layer else 0.0,\n",
    "        reconstruction_weight=1.0,\n",
    "        use_kl_on_final_layer=True,\n",
    "        balance_reconstruction_losses=method is TrainingMethod.next_layer,\n",
    "        use_weighted_mask=False,\n",
    "        method=method,\n",
    "    )\n",
    "    for method in TrainingMethod\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc0137f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from next_layer_sae.training import build_cache\n",
    "\n",
    "if TRAINING_CACHE_DIR and (\n",
    "    not os.path.exists(TRAINING_CACHE_DIR) or not os.listdir(TRAINING_CACHE_DIR)\n",
    "):\n",
    "    build_cache(\n",
    "        TRAINING_CACHE_DIR,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        training_dataset,\n",
    "        tokenizer_batch_size=TOKENIZER_BATCH_SIZE,\n",
    "        inference_batch_size=TRAINING_BATCH_SIZE,\n",
    "        num_tokens=NUM_TRAINING_TOKENS,\n",
    "    )\n",
    "\n",
    "if VALIDATION_CACHE_DIR and (\n",
    "    not os.path.exists(VALIDATION_CACHE_DIR) or not os.listdir(VALIDATION_CACHE_DIR)\n",
    "):\n",
    "    build_cache(\n",
    "        VALIDATION_CACHE_DIR,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        validation_dataset,\n",
    "        tokenizer_batch_size=TOKENIZER_BATCH_SIZE,\n",
    "        inference_batch_size=TRAINING_BATCH_SIZE,\n",
    "        num_tokens=NUM_VALIDATION_TOKENS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a6b425",
   "metadata": {},
   "source": [
    "## Next-layer auxiliary loss (my method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb5c39f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad53dd1f29c4d38a0d55dda3f347217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Layer 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08600ed68d6b49bfa63fcf813620a156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac61b9a72f0346ec9cd61687aa38f6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Layer 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5e779e11d246689cdf87cf66b45ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f2480043474053877e3de74865590d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Layer 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d21eab9ff847ff817f166772cb50fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82fe261aa11404d9c354d56eb32351c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Layer 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fc76bd185f43d49ce3beab255f51d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mAdd next_layer_sae.training.train_e2e @L379\u001b[m\n",
      "\u001b[1m\u001b[33mUpdate next_layer_sae.sae_data.get_sae_data @L179\u001b[m\n",
      "\u001b[1m\u001b[33mUpdate next_layer_sae.sae_data.get_sae_data @L179\u001b[m\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    saes[TrainingMethod.next_layer],\n",
    "    training_dataset,\n",
    "    training_config[TrainingMethod.next_layer],\n",
    "    cache_dir=TRAINING_CACHE_DIR,\n",
    "    reinit_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038ed6e",
   "metadata": {},
   "source": [
    "## Full end-to-end training\n",
    "Recreation of the method SAE_e2e+ds from\n",
    "> Braun, Dan, Jordan Taylor, Nicholas Goldowsky-Dill, and Lee Sharkey. 2024. “Identifying Functionally Important Features with End-to-End Sparse Dictionary Learning.” arXiv [Cs.LG]. arXiv. http://arxiv.org/abs/2405.12241.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82b7287a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816cca5dc9bb4da9974276eb01b9bc14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Layer 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789c27e95f9f4fe9af8a2678908ea812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Layer 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6af7692f19424c86f6de18c698cbce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Layer 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182ff44ed8cb47b899c865803dd6517f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Layer 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a876698f524215a78d062ab6c0f48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    saes[TrainingMethod.e2e],\n",
    "    training_dataset,\n",
    "    training_config[TrainingMethod.e2e],\n",
    "    cache_dir=TRAINING_CACHE_DIR,\n",
    "    reinit_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f2ff90",
   "metadata": {},
   "source": [
    "## End-to-end fine-tuning\n",
    "\n",
    "Recreation of the KL fine-tuning method from\n",
    "> Karvonen, Adam. 2025. “Revisiting End-to-End Sparse Autoencoder Training: A Short Finetune Is All You Need.” arXiv [Cs.LG]. arXiv. http://arxiv.org/abs/2503.17272.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "502354e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c53e742241466faa03237647cd7ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Layer 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df8c3639419493da1bc23a3042bef9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2049eaabaff429992fce0a4913050b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Layer 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d92904a6bf14b66899073abcaf60410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0d89bd5790406d8d77948bed5e28f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Layer 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c4d900f9924b28857d01ec56006525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c484ed1582254eb8a277aee074baf103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Layer 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e063ec446ea455a9b51927edcc60668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    saes[TrainingMethod.finetuned],\n",
    "    training_dataset,\n",
    "    training_config[TrainingMethod.finetuned],\n",
    "    cache_dir=TRAINING_CACHE_DIR,\n",
    "    reinit_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce323e",
   "metadata": {},
   "source": [
    "# Evaluations and comparisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from next_layer_sae.validation import validate_saes\n",
    "\n",
    "all_evals, replacement_evals, position_ids = validate_saes(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    saes[TrainingMethod.e2e],\n",
    "    validation_dataset,\n",
    "    num_tokens=int(1e5),\n",
    "    # num_batches=1,\n",
    "    tokenizer_batch_size=training_config[TrainingMethod.e2e].tokenizer_batch_size,\n",
    "    inference_batch_size=training_config[TrainingMethod.e2e].training_batch_size,\n",
    "    use_next_layer_sae=False,\n",
    "    cache_dir=VALIDATION_CACHE_DIR,\n",
    ")\n",
    "\n",
    "np.set_printoptions(threshold=10_000)\n",
    "\n",
    "# Define colors for each layer\n",
    "colors = [\n",
    "    \"blue\",\n",
    "    \"red\",\n",
    "    \"green\",\n",
    "    \"orange\",\n",
    "    \"purple\",\n",
    "    \"brown\",\n",
    "    \"pink\",\n",
    "    \"gray\",\n",
    "    \"olive\",\n",
    "    \"cyan\",\n",
    "]\n",
    "\n",
    "# Plot histogram of position_ids\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.hist(position_ids, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "# plt.title(\"Distribution of Position IDs\")\n",
    "# plt.xlabel(\"Position ID\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# for plot_vs_pos in [\"rcn\", \"next_rcn\"]:\n",
    "#     # Plot next_rcn vs position_ids\n",
    "#     if plot_vs_pos in all_evals:\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         # Create scatter plot for each layer\n",
    "#         for i, (layer, layer_eval) in enumerate(all_evals[plot_vs_pos].items()):\n",
    "#             plt.scatter(\n",
    "#                 position_ids,\n",
    "#                 layer_eval,\n",
    "#                 alpha=0.6,\n",
    "#                 color=colors[i % len(colors)],\n",
    "#                 label=f\"Layer {layer}\",\n",
    "#                 s=1\n",
    "#             )\n",
    "\n",
    "#         plt.title(f\"{plot_vs_pos} vs Position IDs\")\n",
    "#         plt.xlabel(\"Position ID\")\n",
    "#         plt.ylabel(plot_vs_pos)\n",
    "#         plt.legend()\n",
    "#         plt.grid(True, alpha=0.3)\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "\n",
    "#     # Plot mean next_rcn vs position_ids\n",
    "#     if plot_vs_pos in all_evals:\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "\n",
    "#         # Calculate mean next_rcn for each position and layer\n",
    "#         for i, (layer, layer_eval) in enumerate(all_evals[plot_vs_pos].items()):\n",
    "#             # Create a dictionary to store values for each position\n",
    "#             position_values = {}\n",
    "\n",
    "#             # Group values by position\n",
    "#             for pos, val in zip(position_ids[:len(layer_eval)], layer_eval):\n",
    "#                 if pos not in position_values:\n",
    "#                     position_values[pos] = []\n",
    "#                 position_values[pos].append(val)\n",
    "\n",
    "#             # Calculate mean for each position\n",
    "#             positions = sorted(position_values.keys())\n",
    "#             mean_values = [np.mean(position_values[pos]) for pos in positions]\n",
    "\n",
    "#             plt.plot(\n",
    "#                 positions,\n",
    "#                 mean_values,\n",
    "#                 color=colors[i % len(colors)],\n",
    "#                 label=f\"Layer {layer}\",\n",
    "#                 linewidth=2,\n",
    "#                 marker='o',\n",
    "#                 markersize=3\n",
    "#             )\n",
    "\n",
    "#         plt.title(f\"Mean {plot_vs_pos} vs Position IDs\")\n",
    "#         plt.xlabel(\"Position ID\")\n",
    "#         plt.ylabel(f\"Mean {plot_vs_pos}\")\n",
    "#         plt.legend()\n",
    "#         plt.grid(True, alpha=0.3)\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "\n",
    "for key in all_evals.keys():\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Create overlapping histograms on the same plot\n",
    "    for i, (layer, layer_eval) in reversed(list(enumerate(all_evals[key].items()))):\n",
    "        plt.hist(\n",
    "            layer_eval,\n",
    "            bins=50,\n",
    "            alpha=0.7,\n",
    "            edgecolor=\"black\",\n",
    "            color=colors[i % len(colors)],\n",
    "            label=f\"Layer {layer}\",\n",
    "        )\n",
    "    plt.title(f\"{key} distribution comparison\")\n",
    "    plt.xlabel(key)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "# Plot replacement evaluation metrics\n",
    "print(\"Replacement evaluation metrics:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for key, value in replacement_evals.items():\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.hist(\n",
    "        value,\n",
    "        bins=50,\n",
    "        alpha=0.7,\n",
    "        edgecolor=\"black\",\n",
    "        color=\"blue\",\n",
    "    )\n",
    "    plt.title(f\"{key} distribution\")\n",
    "    plt.xlabel(key)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    print(f\"{key}: mean = {np.mean(value):.6f}\")\n",
    "\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# Print mean values for each evaluation metric\n",
    "print(\"Mean evaluation metrics:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for key in all_evals.keys():\n",
    "    print(f\"{key}:\")\n",
    "    for layer, layer_eval in reversed(all_evals[key].items()):\n",
    "        mean = np.mean(layer_eval)\n",
    "        print(f\"  Layer {layer}: {mean:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
